{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'py' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'py' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'py' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'py' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!py -m pip install pandas\n",
    "!py -m pip install numpy\n",
    "!py -m pip install matplotlib\n",
    "!py -m pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "import spacy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "nlp = spacy.cli.download('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spam</td>\n",
       "      <td>viiiiiiagraaaa\\r\\nonly for the ones that want ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ham</td>\n",
       "      <td>got ice thought look az original message ice o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spam</td>\n",
       "      <td>yo ur wom an ne eds an escapenumber in ch ma n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spam</td>\n",
       "      <td>start increasing your odds of success &amp; live s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ham</td>\n",
       "      <td>author jra date escapenumber escapenumber esca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193847</th>\n",
       "      <td>Ham</td>\n",
       "      <td>on escapenumber escapenumber escapenumber rob ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193848</th>\n",
       "      <td>Spam</td>\n",
       "      <td>we have everything you need escapelong cialesc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193849</th>\n",
       "      <td>Ham</td>\n",
       "      <td>hi quick question say i have a date variable i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193850</th>\n",
       "      <td>Spam</td>\n",
       "      <td>thank you for your loan request which we recie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193851</th>\n",
       "      <td>Ham</td>\n",
       "      <td>this is an automatically generated delivery st...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>193852 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                               text\n",
       "0       Spam  viiiiiiagraaaa\\r\\nonly for the ones that want ...\n",
       "1        Ham  got ice thought look az original message ice o...\n",
       "2       Spam  yo ur wom an ne eds an escapenumber in ch ma n...\n",
       "3       Spam  start increasing your odds of success & live s...\n",
       "4        Ham  author jra date escapenumber escapenumber esca...\n",
       "...      ...                                                ...\n",
       "193847   Ham  on escapenumber escapenumber escapenumber rob ...\n",
       "193848  Spam  we have everything you need escapelong cialesc...\n",
       "193849   Ham  hi quick question say i have a date variable i...\n",
       "193850  Spam  thank you for your loan request which we recie...\n",
       "193851   Ham  this is an automatically generated delivery st...\n",
       "\n",
       "[193852 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"spam_Emails_data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label         2\n",
       "text     193848\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spam</td>\n",
       "      <td>viiiiiiagraaaa\\r\\nonly for the ones that want ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ham</td>\n",
       "      <td>got ice thought look az original message ice o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spam</td>\n",
       "      <td>yo ur wom an ne eds an escapenumber in ch ma n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spam</td>\n",
       "      <td>start increasing your odds of success &amp; live s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ham</td>\n",
       "      <td>author jra date escapenumber escapenumber esca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193847</th>\n",
       "      <td>Ham</td>\n",
       "      <td>on escapenumber escapenumber escapenumber rob ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193848</th>\n",
       "      <td>Spam</td>\n",
       "      <td>we have everything you need escapelong cialesc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193849</th>\n",
       "      <td>Ham</td>\n",
       "      <td>hi quick question say i have a date variable i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193850</th>\n",
       "      <td>Spam</td>\n",
       "      <td>thank you for your loan request which we recie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193851</th>\n",
       "      <td>Ham</td>\n",
       "      <td>this is an automatically generated delivery st...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>193849 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                               text\n",
       "0       Spam  viiiiiiagraaaa\\r\\nonly for the ones that want ...\n",
       "1        Ham  got ice thought look az original message ice o...\n",
       "2       Spam  yo ur wom an ne eds an escapenumber in ch ma n...\n",
       "3       Spam  start increasing your odds of success & live s...\n",
       "4        Ham  author jra date escapenumber escapenumber esca...\n",
       "...      ...                                                ...\n",
       "193847   Ham  on escapenumber escapenumber escapenumber rob ...\n",
       "193848  Spam  we have everything you need escapelong cialesc...\n",
       "193849   Ham  hi quick question say i have a date variable i...\n",
       "193850  Spam  thank you for your loan request which we recie...\n",
       "193851   Ham  this is an automatically generated delivery st...\n",
       "\n",
       "[193849 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop_duplicates('text')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label    False\n",
       "text      True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spam</td>\n",
       "      <td>viiiiiiagraaaa\\r\\nonly for the ones that want ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ham</td>\n",
       "      <td>got ice thought look az original message ice o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spam</td>\n",
       "      <td>yo ur wom an ne eds an escapenumber in ch ma n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spam</td>\n",
       "      <td>start increasing your odds of success &amp; live s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ham</td>\n",
       "      <td>author jra date escapenumber escapenumber esca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193847</th>\n",
       "      <td>Ham</td>\n",
       "      <td>on escapenumber escapenumber escapenumber rob ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193848</th>\n",
       "      <td>Spam</td>\n",
       "      <td>we have everything you need escapelong cialesc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193849</th>\n",
       "      <td>Ham</td>\n",
       "      <td>hi quick question say i have a date variable i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193850</th>\n",
       "      <td>Spam</td>\n",
       "      <td>thank you for your loan request which we recie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193851</th>\n",
       "      <td>Ham</td>\n",
       "      <td>this is an automatically generated delivery st...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>193848 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                               text\n",
       "0       Spam  viiiiiiagraaaa\\r\\nonly for the ones that want ...\n",
       "1        Ham  got ice thought look az original message ice o...\n",
       "2       Spam  yo ur wom an ne eds an escapenumber in ch ma n...\n",
       "3       Spam  start increasing your odds of success & live s...\n",
       "4        Ham  author jra date escapenumber escapenumber esca...\n",
       "...      ...                                                ...\n",
       "193847   Ham  on escapenumber escapenumber escapenumber rob ...\n",
       "193848  Spam  we have everything you need escapelong cialesc...\n",
       "193849   Ham  hi quick question say i have a date variable i...\n",
       "193850  Spam  thank you for your loan request which we recie...\n",
       "193851   Ham  this is an automatically generated delivery st...\n",
       "\n",
       "[193848 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(10)\n",
    "\n",
    "rand_idx = set()\n",
    "while len(rand_idx) < 70000:\n",
    "    rand_idx.add(random.randint(0, len(df)-1))\n",
    "    \n",
    "# Select the rows from df\n",
    "df = df.iloc[list(rand_idx)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       label                                               text\n",
      "0       Spam  viiiiiiagraaaa\\r\\nonly for the ones that want ...\n",
      "131075   Ham  london accounting group informed us needed tra...\n",
      "131076   Ham  subject 200 summary reduplication month christ...\n",
      "3       Spam  start increasing your odds of success & live s...\n",
      "1        Ham  got ice thought look az original message ice o...\n",
      "...      ...                                                ...\n",
      "131065   Ham   subject this was in the miami times this morn...\n",
      "131067   Ham  fyi . this market is crazy . . .\\r\\n- - - - - ...\n",
      "131070  Spam  alrite sick of feeling left out want to experi...\n",
      "131071  Spam  i am engineer mr duke donard staff of one of t...\n",
      "131073   Ham  see http finzi psych upenn edu r rhelpescapenu...\n",
      "\n",
      "[70000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label    False\n",
       "text     False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(df)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 70000 entries, 0 to 131073\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   label   70000 non-null  object\n",
      " 1   text    70000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing with spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spam</td>\n",
       "      <td>viiiiiiagraaaa\\r\\nonly for the ones that want ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131075</th>\n",
       "      <td>Ham</td>\n",
       "      <td>london accounting group informed us needed tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131076</th>\n",
       "      <td>Ham</td>\n",
       "      <td>subject 200 summary reduplication month christ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spam</td>\n",
       "      <td>start increasing your odds of success &amp; live s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ham</td>\n",
       "      <td>got ice thought look az original message ice o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                               text\n",
       "0       Spam  viiiiiiagraaaa\\r\\nonly for the ones that want ...\n",
       "131075   Ham  london accounting group informed us needed tra...\n",
       "131076   Ham  subject 200 summary reduplication month christ...\n",
       "3       Spam  start increasing your odds of success & live s...\n",
       "1        Ham  got ice thought look az original message ice o..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "Ham     36932\n",
       "Spam    33068\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70000/70000 [52:56<00:00, 22.04it/s]   \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spam</td>\n",
       "      <td>viiiiiiagraaaa one want scream prodigy scrawny...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131075</th>\n",
       "      <td>Ham</td>\n",
       "      <td>london accounting group inform need transfer p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131076</th>\n",
       "      <td>Ham</td>\n",
       "      <td>subject summary reduplication month christmas ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spam</td>\n",
       "      <td>start increase odd success live sexually healt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ham</td>\n",
       "      <td>get ice think look az original message ice ope...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                               text\n",
       "0       Spam  viiiiiiagraaaa one want scream prodigy scrawny...\n",
       "131075   Ham  london accounting group inform need transfer p...\n",
       "131076   Ham  subject summary reduplication month christmas ...\n",
       "3       Spam  start increase odd success live sexually healt...\n",
       "1        Ham  get ice think look az original message ice ope..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import spacy\n",
    "from tqdm import tqdm  # For progress tracking\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Function to clean text by removing special characters, stopwords, and applying lemmatization\n",
    "def clean_text(text):\n",
    "    # Remove special characters using regex\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Retain only letters and spaces\n",
    "    # Process the text with spaCy\n",
    "    doc = nlp(text.lower())  # Convert to lowercase\n",
    "    # Filter tokens: Remove stopwords and apply lemmatization\n",
    "    filtered_words = [token.lemma_ for token in doc if not token.is_stop and token.is_alpha]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "# Apply text cleaning to each specified column using spaCy's nlp.pipe for batch processing\n",
    "columns_to_process = ['text']\n",
    "for column in columns_to_process:\n",
    "    tqdm.pandas()  # Enable progress bar for apply function\n",
    "    df[column] = df[column].astype(str).progress_apply(clean_text)\n",
    "\n",
    "# Display the first few rows of the cleaned DataFrame\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spam</td>\n",
       "      <td>viiiiiiagraaaa one want scream prodigy scrawny...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ham</td>\n",
       "      <td>london accounting group inform need transfer p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ham</td>\n",
       "      <td>subject summary reduplication month christmas ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spam</td>\n",
       "      <td>start increase odd success live sexually healt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ham</td>\n",
       "      <td>get ice think look az original message ice ope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69995</th>\n",
       "      <td>Ham</td>\n",
       "      <td>subject miami time morning leonard pitts jr sy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69996</th>\n",
       "      <td>Ham</td>\n",
       "      <td>fyi market crazy original message comne alan s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69997</th>\n",
       "      <td>Spam</td>\n",
       "      <td>alrite sick feeling leave want experience unbe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69998</th>\n",
       "      <td>Spam</td>\n",
       "      <td>engineer mr duke donard staff influential bank...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69999</th>\n",
       "      <td>Ham</td>\n",
       "      <td>http finzi psych upenn edu r rhelpescapenumber...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text\n",
       "0      Spam  viiiiiiagraaaa one want scream prodigy scrawny...\n",
       "1       Ham  london accounting group inform need transfer p...\n",
       "2       Ham  subject summary reduplication month christmas ...\n",
       "3      Spam  start increase odd success live sexually healt...\n",
       "4       Ham  get ice think look az original message ice ope...\n",
       "...     ...                                                ...\n",
       "69995   Ham  subject miami time morning leonard pitts jr sy...\n",
       "69996   Ham  fyi market crazy original message comne alan s...\n",
       "69997  Spam  alrite sick feeling leave want experience unbe...\n",
       "69998  Spam  engineer mr duke donard staff influential bank...\n",
       "69999   Ham  http finzi psych upenn edu r rhelpescapenumber...\n",
       "\n",
       "[70000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"cleaned_data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "Spam    33068\n",
      "Ham     33068\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Separate the classes\n",
    "spam = df[df['label'] == 'Spam']\n",
    "ham = df[df['label'] == 'Ham']\n",
    "\n",
    "# Downsample the 'ham' class to match the size of the 'spam' class\n",
    "ham_downsampled = ham.sample(len(spam), random_state=42)\n",
    "\n",
    "# Combine the downsampled 'ham' class with the 'spam' class\n",
    "balanced_df = pd.concat([spam, ham_downsampled])\n",
    "\n",
    "# Shuffle the balanced dataset\n",
    "balanced_df = balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Display the balanced label counts\n",
    "print(balanced_df['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spam</td>\n",
       "      <td>viiiiiiagraaaa one want scream prodigy scrawny...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ham</td>\n",
       "      <td>london accounting group inform need transfer p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ham</td>\n",
       "      <td>subject summary reduplication month christmas ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spam</td>\n",
       "      <td>start increase odd success live sexually healt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ham</td>\n",
       "      <td>get ice think look az original message ice ope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69995</th>\n",
       "      <td>Ham</td>\n",
       "      <td>subject miami time morning leonard pitts jr sy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69996</th>\n",
       "      <td>Ham</td>\n",
       "      <td>fyi market crazy original message comne alan s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69997</th>\n",
       "      <td>Spam</td>\n",
       "      <td>alrite sick feeling leave want experience unbe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69998</th>\n",
       "      <td>Spam</td>\n",
       "      <td>engineer mr duke donard staff influential bank...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69999</th>\n",
       "      <td>Ham</td>\n",
       "      <td>http finzi psych upenn edu r rhelpescapenumber...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69948 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text\n",
       "0      Spam  viiiiiiagraaaa one want scream prodigy scrawny...\n",
       "1       Ham  london accounting group inform need transfer p...\n",
       "2       Ham  subject summary reduplication month christmas ...\n",
       "3      Spam  start increase odd success live sexually healt...\n",
       "4       Ham  get ice think look az original message ice ope...\n",
       "...     ...                                                ...\n",
       "69995   Ham  subject miami time morning leonard pitts jr sy...\n",
       "69996   Ham  fyi market crazy original message comne alan s...\n",
       "69997  Spam  alrite sick feeling leave want experience unbe...\n",
       "69998  Spam  engineer mr duke donard staff influential bank...\n",
       "69999   Ham  http finzi psych upenn edu r rhelpescapenumber...\n",
       "\n",
       "[69948 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop rows where 'text' column is NaN\n",
    "df = df.dropna(subset=['text'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    aa   ab  ability  able  absence  absolutely  abstract  abuse   ac  accept  \\\n",
      "0  0.0  0.0      0.0   0.0      0.0         0.0       0.0    0.0  0.0     0.0   \n",
      "1  0.0  0.0      0.0   0.0      0.0         0.0       0.0    0.0  0.0     0.0   \n",
      "2  0.0  0.0      0.0   0.0      0.0         0.0       0.0    0.0  0.0     0.0   \n",
      "3  0.0  0.0      0.0   0.0      0.0         0.0       0.0    0.0  0.0     0.0   \n",
      "4  0.0  0.0      0.0   0.0      0.0         0.0       0.0    0.0  0.0     0.0   \n",
      "\n",
      "   ...  yesterday  yield   yo  york  young  zero  zescapenumberr  \\\n",
      "0  ...        0.0    0.0  0.0   0.0    0.0   0.0             0.0   \n",
      "1  ...        0.0    0.0  0.0   0.0    0.0   0.0             0.0   \n",
      "2  ...        0.0    0.0  0.0   0.0    0.0   0.0             0.0   \n",
      "3  ...        0.0    0.0  0.0   0.0    0.0   0.0             0.0   \n",
      "4  ...        0.0    0.0  0.0   0.0    0.0   0.0             0.0   \n",
      "\n",
      "   zescapenumberrm  zescapenumbert  zone  \n",
      "0              0.0             0.0   0.0  \n",
      "1              0.0             0.0   0.0  \n",
      "2              0.0             0.0   0.0  \n",
      "3              0.0             0.0   0.0  \n",
      "4              0.0             0.0   0.0  \n",
      "\n",
      "[5 rows x 3000 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize TF-IDF Vectorizer\n",
    "tfidf = TfidfVectorizer(max_features=3000, stop_words='english')  # Set max_features as needed\n",
    "\n",
    "# Fit and transform the 'text' column\n",
    "tfidf_matrix = tfidf.fit_transform(df['text'])\n",
    "\n",
    "# Convert the TF-IDF matrix to a dense array (optional)\n",
    "tfidf_array = tfidf_matrix.toarray()\n",
    "\n",
    "# Create a DataFrame for the TF-IDF features\n",
    "tfidf_df = pd.DataFrame(tfidf_array, columns=tfidf.get_feature_names_out())\n",
    "\n",
    "# Display the TF-IDF DataFram\n",
    "print(tfidf_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "np.nan is an invalid document, expected byte or unicode string.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m balanced_reviews \u001b[38;5;241m=\u001b[39m balanced_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Refit and transform the reviews in the balanced dataset\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m tfidf_balanced_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mtfidf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbalanced_reviews\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Convert to dense array and create a TF-IDF DataFrame\u001b[39;00m\n\u001b[0;32m      8\u001b[0m tfidf_balanced_array \u001b[38;5;241m=\u001b[39m tfidf_balanced_matrix\u001b[38;5;241m.\u001b[39mtoarray()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\feature_extraction\\text.py:2091\u001b[0m, in \u001b[0;36mTfidfVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   2084\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params()\n\u001b[0;32m   2085\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf \u001b[38;5;241m=\u001b[39m TfidfTransformer(\n\u001b[0;32m   2086\u001b[0m     norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm,\n\u001b[0;32m   2087\u001b[0m     use_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_idf,\n\u001b[0;32m   2088\u001b[0m     smooth_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msmooth_idf,\n\u001b[0;32m   2089\u001b[0m     sublinear_tf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msublinear_tf,\n\u001b[0;32m   2090\u001b[0m )\n\u001b[1;32m-> 2091\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2092\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf\u001b[38;5;241m.\u001b[39mfit(X)\n\u001b[0;32m   2093\u001b[0m \u001b[38;5;66;03m# X is already a transformed view of raw_documents so\u001b[39;00m\n\u001b[0;32m   2094\u001b[0m \u001b[38;5;66;03m# we set copy to False\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\feature_extraction\\text.py:1372\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1364\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1365\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper case characters found in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1366\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vocabulary while \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1367\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is True. These entries will not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1368\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be matched with any documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1369\u001b[0m             )\n\u001b[0;32m   1370\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1372\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_vocabulary_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[0;32m   1375\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\feature_extraction\\text.py:1259\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1257\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m raw_documents:\n\u001b[0;32m   1258\u001b[0m     feature_counter \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m-> 1259\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m \u001b[43manalyze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1260\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1261\u001b[0m             feature_idx \u001b[38;5;241m=\u001b[39m vocabulary[feature]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\feature_extraction\\text.py:103\u001b[0m, in \u001b[0;36m_analyze\u001b[1;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Chain together an optional series of text processing steps to go from\u001b[39;00m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;124;03ma single document to ngrams, with or without tokenizing or preprocessing.\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;124;03m    A sequence of tokens, possibly with pairs, triples, etc.\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m decoder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 103\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m analyzer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    105\u001b[0m     doc \u001b[38;5;241m=\u001b[39m analyzer(doc)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\feature_extraction\\text.py:236\u001b[0m, in \u001b[0;36m_VectorizerMixin.decode\u001b[1;34m(self, doc)\u001b[0m\n\u001b[0;32m    233\u001b[0m     doc \u001b[38;5;241m=\u001b[39m doc\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecode_error)\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m doc \u001b[38;5;129;01mis\u001b[39;00m np\u001b[38;5;241m.\u001b[39mnan:\n\u001b[1;32m--> 236\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    237\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnp.nan is an invalid document, expected byte or unicode string.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    238\u001b[0m     )\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m doc\n",
      "\u001b[1;31mValueError\u001b[0m: np.nan is an invalid document, expected byte or unicode string."
     ]
    }
   ],
   "source": [
    "# Ensure the TF-IDF DataFrame and balanced dataset are aligned\n",
    "balanced_reviews = balanced_df['text']\n",
    "\n",
    "# Refit and transform the reviews in the balanced dataset\n",
    "tfidf_balanced_matrix = tfidf.fit_transform(balanced_reviews)\n",
    "\n",
    "# Convert to dense array and create a TF-IDF DataFrame\n",
    "tfidf_balanced_array = tfidf_balanced_matrix.toarray()\n",
    "tfidf_balanced_df = pd.DataFrame(tfidf_balanced_array, columns=tfidf.get_feature_names_out())\n",
    "\n",
    "# Add the 'label' column back to the final dataset\n",
    "tfidf_balanced_df['label'] = balanced_df['label'].values\n",
    "\n",
    "# Display the final dataset\n",
    "print(tfidf_balanced_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\lisoh\\appdata\\roaming\\python\\python39\\site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\lisoh\\appdata\\roaming\\python\\python39\\site-packages (from scikit-learn) (2.0.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\lisoh\\appdata\\roaming\\python\\python39\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\lisoh\\appdata\\roaming\\python\\python39\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\lisoh\\appdata\\roaming\\python\\python39\\site-packages (from scikit-learn) (1.13.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python39_64\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "     -------------------------------------- 294.9/294.9 KB 4.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\lisoh\\appdata\\roaming\\python\\python39\\site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\lisoh\\appdata\\roaming\\python\\python39\\site-packages (from seaborn) (3.9.3)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\lisoh\\appdata\\roaming\\python\\python39\\site-packages (from seaborn) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\lisoh\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\lisoh\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\lisoh\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\lisoh\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.0.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\lisoh\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\lisoh\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\lisoh\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\lisoh\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.55.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\lisoh\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (6.4.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lisoh\\appdata\\roaming\\python\\python39\\site-packages (from pandas>=1.2->seaborn) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\lisoh\\appdata\\roaming\\python\\python39\\site-packages (from pandas>=1.2->seaborn) (2024.2)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\lisoh\\appdata\\roaming\\python\\python39\\site-packages (from importlib-resources>=3.2.0->matplotlib!=3.6.1,>=3.4->seaborn) (3.20.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lisoh\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python39_64\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!py -m pip install scikit-learn\n",
    "!py -m pip install seaborn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tfidf_balanced_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Create a copy of the DataFrame\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df_s \u001b[38;5;241m=\u001b[39m \u001b[43mtfidf_balanced_df\u001b[49m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m      3\u001b[0m df_s\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tfidf_balanced_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Create a copy of the DataFrame\n",
    "df_s = tfidf_balanced_df.copy()\n",
    "df_s.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SUPERVISED LEARNING - LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting xgboost\n",
      "  Downloading xgboost-2.1.3-py3-none-win_amd64.whl (124.9 MB)\n",
      "     ------------------------------------- 124.9/124.9 MB 10.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scipy in c:\\users\\lisoh\\appdata\\roaming\\python\\python39\\site-packages (from xgboost) (1.13.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\lisoh\\appdata\\roaming\\python\\python39\\site-packages (from xgboost) (2.0.2)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-2.1.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python39_64\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!py -m pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tfidf_balanced_df.drop(columns=['label'])\n",
    "y = tfidf_balanced_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    aa   ab  ability  able  absence  absolutely  abstract  abuse   ac  accept  \\\n",
      "0  0.0  0.0      0.0   0.0      0.0         0.0       0.0    0.0  0.0     0.0   \n",
      "1  0.0  0.0      0.0   0.0      0.0         0.0       0.0    0.0  0.0     0.0   \n",
      "2  0.0  0.0      0.0   0.0      0.0         0.0       0.0    0.0  0.0     0.0   \n",
      "3  0.0  0.0      0.0   0.0      0.0         0.0       0.0    0.0  0.0     0.0   \n",
      "4  0.0  0.0      0.0   0.0      0.0         0.0       0.0    0.0  0.0     0.0   \n",
      "\n",
      "   ...  yesterday  yield   yo  york  young  zero  zescapenumberr  \\\n",
      "0  ...        0.0    0.0  0.0   0.0    0.0   0.0             0.0   \n",
      "1  ...        0.0    0.0  0.0   0.0    0.0   0.0             0.0   \n",
      "2  ...        0.0    0.0  0.0   0.0    0.0   0.0             0.0   \n",
      "3  ...        0.0    0.0  0.0   0.0    0.0   0.0             0.0   \n",
      "4  ...        0.0    0.0  0.0   0.0    0.0   0.0             0.0   \n",
      "\n",
      "   zescapenumberrm  zescapenumbert  zone  \n",
      "0              0.0             0.0   0.0  \n",
      "1              0.0             0.0   0.0  \n",
      "2              0.0             0.0   0.0  \n",
      "3              0.0             0.0   0.0  \n",
      "4              0.0             0.0   0.0  \n",
      "\n",
      "[5 rows x 2999 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(X.head())\n",
    "print(type(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(X, pd.Series):\n",
    "    X = X.to_frame()  # Convert Series to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (46295, 2999)\n",
      "Shape of y_train: (46295,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of X_train: {X_train.shape}\")\n",
    "print(f\"Shape of y_train: {y_train.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Results:\n",
      "Accuracy: 0.9626\n",
      "Confusion Matrix:\n",
      "[[9412  465]\n",
      " [ 277 9687]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Ham       0.97      0.95      0.96      9877\n",
      "        Spam       0.95      0.97      0.96      9964\n",
      "\n",
      "    accuracy                           0.96     19841\n",
      "   macro avg       0.96      0.96      0.96     19841\n",
      "weighted avg       0.96      0.96      0.96     19841\n",
      "\n",
      "Cross-Validation Accuracy: 0.9627 ± 0.0018\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the Logistic Regression model with class weights\n",
    "# better dun run\n",
    "lr_model = LogisticRegression(class_weight='balanced')\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = lr_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Generate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print metrics\n",
    "print(f\"Logistic Regression Results:\\nAccuracy: {accuracy:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Generate a detailed classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Perform 3-fold cross-validation\n",
    "cv_scores = cross_val_score(lr_model, X, y, cv=3, scoring='accuracy')\n",
    "print(f\"Cross-Validation Accuracy: {cv_scores.mean():.4f} ± {cv_scores.std():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Results:\n",
      "Accuracy: 0.9705\n",
      "Confusion Matrix:\n",
      "[[9610  267]\n",
      " [ 319 9645]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Ham       0.97      0.97      0.97      9877\n",
      "        Spam       0.97      0.97      0.97      9964\n",
      "\n",
      "    accuracy                           0.97     19841\n",
      "   macro avg       0.97      0.97      0.97     19841\n",
      "weighted avg       0.97      0.97      0.97     19841\n",
      "\n",
      "Cross-Validation Accuracy: 0.9735 ± 0.0008\n"
     ]
    }
   ],
   "source": [
    "# Define the Random Forest model\n",
    "rf_model = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Random Forest Results:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_rf):.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_rf))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "\n",
    "# Perform 3-fold cross-validation\n",
    "cv_scores = cross_val_score(rf_model, X, y, cv=3, scoring='accuracy')\n",
    "print(f\"Cross-Validation Accuracy: {cv_scores.mean():.4f} ± {cv_scores.std():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Results:\n",
      "Accuracy: 0.9645\n",
      "Confusion Matrix:\n",
      "[[9544  333]\n",
      " [ 372 9592]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Ham       0.96      0.97      0.96      9877\n",
      "        Spam       0.97      0.96      0.96      9964\n",
      "\n",
      "    accuracy                           0.96     19841\n",
      "   macro avg       0.96      0.96      0.96     19841\n",
      "weighted avg       0.96      0.96      0.96     19841\n",
      "\n",
      "Cross-Validation Accuracy: 0.9697 ± 0.0022\n"
     ]
    }
   ],
   "source": [
    "# Define the Neural Network model\n",
    "mlp_model = MLPClassifier(hidden_layer_sizes=(100,), max_iter=300, random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "mlp_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_mlp = mlp_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Neural Network Results:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_mlp):.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_mlp))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_mlp))\n",
    "\n",
    "# Perform 3-fold cross-validation\n",
    "cv_scores = cross_val_score(mlp_model, X, y, cv=3, scoring='accuracy')\n",
    "print(f\"Cross-Validation Accuracy: {cv_scores.mean():.4f} ± {cv_scores.std():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Results:\n",
      "Accuracy: 0.9309\n",
      "Confusion Matrix:\n",
      "[[9335  542]\n",
      " [ 829 9135]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Ham       0.92      0.95      0.93      9877\n",
      "        Spam       0.94      0.92      0.93      9964\n",
      "\n",
      "    accuracy                           0.93     19841\n",
      "   macro avg       0.93      0.93      0.93     19841\n",
      "weighted avg       0.93      0.93      0.93     19841\n",
      "\n",
      "Cross-Validation Accuracy: 0.9342 ± 0.0062\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Initialize and train the Naive Bayes model\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_nb = nb_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
    "\n",
    "# Generate confusion matrix\n",
    "conf_matrix_nb = confusion_matrix(y_test, y_pred_nb)\n",
    "\n",
    "# Print metrics\n",
    "print(f\"Naive Bayes Results:\\nAccuracy: {accuracy_nb:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_nb)\n",
    "\n",
    "# Generate a detailed classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "\n",
    "# Perform 3-fold cross-validation\n",
    "cv_scores_nb = cross_val_score(nb_model, X, y, cv=3, scoring='accuracy')\n",
    "print(f\"Cross-Validation Accuracy: {cv_scores_nb.mean():.4f} ± {cv_scores_nb.std():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Visualize the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot confusion matrix as a heatmap\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=mlp_model.classes_, yticklabels=mlp_model.classes_)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'C': [1, 10, 100],  # Regularization strength\n",
    "    #'solver': ['liblinear', 'lbfgs', 'saga'],  # Optimization solvers\n",
    "    #'class_weight': [None, 'balanced'],  # Class weights\n",
    "    'max_iter': [100, 500, 1000],  # Maximum number of iterations\n",
    "}\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "lr_model = LogisticRegression()\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=lr_model,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,\n",
    "    verbose=True,  # Display progress\n",
    "    n_jobs=-1  # Use all available CPU cores\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lisoh\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "15 fits failed out of a total of 27.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "8 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\lisoh\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\lisoh\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\lisoh\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1223, in fit\n",
      "    X, y = self._validate_data(\n",
      "  File \"C:\\Users\\lisoh\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py\", line 650, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\lisoh\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 1301, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"C:\\Users\\lisoh\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 1012, in check_array\n",
      "    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n",
      "  File \"C:\\Users\\lisoh\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\_array_api.py\", line 745, in _asarray_with_order\n",
      "    array = numpy.asarray(array, order=order, dtype=dtype)\n",
      "  File \"C:\\Users\\lisoh\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\generic.py\", line 2152, in __array__\n",
      "    values = self._values\n",
      "  File \"C:\\Users\\lisoh\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\frame.py\", line 1127, in _values\n",
      "    return ensure_wrapped_if_datetimelike(self.values)\n",
      "  File \"C:\\Users\\lisoh\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\frame.py\", line 12664, in values\n",
      "    return self._mgr.as_array()\n",
      "  File \"C:\\Users\\lisoh\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\internals\\managers.py\", line 1694, in as_array\n",
      "    arr = self._interleave(dtype=dtype, na_value=na_value)\n",
      "  File \"C:\\Users\\lisoh\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\internals\\managers.py\", line 1727, in _interleave\n",
      "    result = np.empty(self.shape, dtype=dtype)\n",
      "numpy._core._exceptions._ArrayMemoryError: Unable to allocate 706. MiB for an array with shape (2999, 30863) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\lisoh\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\lisoh\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\lisoh\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1223, in fit\n",
      "    X, y = self._validate_data(\n",
      "  File \"C:\\Users\\lisoh\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py\", line 650, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\lisoh\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 1301, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"C:\\Users\\lisoh\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 1012, in check_array\n",
      "    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n",
      "  File \"C:\\Users\\lisoh\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\_array_api.py\", line 745, in _asarray_with_order\n",
      "    array = numpy.asarray(array, order=order, dtype=dtype)\n",
      "  File \"C:\\Users\\lisoh\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\generic.py\", line 2152, in __array__\n",
      "    values = self._values\n",
      "  File \"C:\\Users\\lisoh\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\frame.py\", line 1127, in _values\n",
      "    return ensure_wrapped_if_datetimelike(self.values)\n",
      "  File \"C:\\Users\\lisoh\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\frame.py\", line 12664, in values\n",
      "    return self._mgr.as_array()\n",
      "  File \"C:\\Users\\lisoh\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\internals\\managers.py\", line 1694, in as_array\n",
      "    arr = self._interleave(dtype=dtype, na_value=na_value)\n",
      "  File \"C:\\Users\\lisoh\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\internals\\managers.py\", line 1727, in _interleave\n",
      "    result = np.empty(self.shape, dtype=dtype)\n",
      "numpy._core._exceptions._ArrayMemoryError: Unable to allocate 706. MiB for an array with shape (2999, 30864) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\lisoh\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\lisoh\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\lisoh\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1223, in fit\n",
      "    X, y = self._validate_data(\n",
      "  File \"C:\\Users\\lisoh\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py\", line 650, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\lisoh\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 1301, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"C:\\Users\\lisoh\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 1012, in check_array\n",
      "    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n",
      "  File \"C:\\Users\\lisoh\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\_array_api.py\", line 745, in _asarray_with_order\n",
      "    array = numpy.asarray(array, order=order, dtype=dtype)\n",
      "numpy._core._exceptions._ArrayMemoryError: Unable to allocate 706. MiB for an array with shape (30863, 2999) and data type float64\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\lisoh\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_search.py:1103: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan 0.96340858        nan\n",
      "        nan        nan 0.96139972]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 10, 'max_iter': 500}\n",
      "Best Cross-Validation Accuracy: 0.9634\n"
     ]
    }
   ],
   "source": [
    "# Perform the grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(f\"Best Cross-Validation Accuracy: {grid_search.best_score_:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy after tuning: 0.9659\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the best model on the test set\n",
    "best_lr_model = grid_search.best_estimator_\n",
    "y_pred = best_lr_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy on the test set\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Logistic Regression Accuracy after tuning: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[9484  393]\n",
      " [ 283 9681]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Ham       0.97      0.96      0.97      9877\n",
      "        Spam       0.96      0.97      0.97      9964\n",
      "\n",
      "    accuracy                           0.97     19841\n",
      "   macro avg       0.97      0.97      0.97     19841\n",
      "weighted avg       0.97      0.97      0.97     19841\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate and print confusion matrix and classification report\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],  # Number of trees\n",
    "    'max_depth': [None, 10, 20, 30],  # Maximum depth of trees\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum samples to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4],  # Minimum samples at a leaf node\n",
    "    'max_features': ['sqrt', 'log2'],  # Number of features to consider for split\n",
    "    'class_weight': ['balanced', 'balanced_subsample'],  # Class weight\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf_model,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,  # 3-fold cross-validation\n",
    "    scoring='accuracy',  # Optimize for accuracy\n",
    "    verbose=True,  # Display progress\n",
    "    n_jobs=-1  # Use all available CPU cores\n",
    ")\n",
    "\n",
    "# Perform the grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(f\"Best Cross-Validation Accuracy: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "y_pred_rf = best_rf_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy on the test set\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Test Set Accuracy: {accuracy_rf:.4f}\")\n",
    "\n",
    "# Generate and print confusion matrix and classification report\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_rf))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (100, 50), (150, 100, 50)],  # Different layer architectures\n",
    "    'activation': ['tanh', 'relu'],  # Activation functions\n",
    "    'solver': ['sgd', 'adam'],  # Solvers for optimization\n",
    "    'alpha': [0.0001, 0.001, 0.01],  # L2 regularization parameter\n",
    "    'learning_rate_init': [0.001, 0.01, 0.1],  # Initial learning rate\n",
    "    'max_iter': [200, 300]  # Number of iterations\n",
    "}\n",
    "\n",
    "# Initialize the MLP model\n",
    "mlp_model = MLPClassifier(random_state=42)\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=mlp_model,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,  # 3-fold cross-validation\n",
    "    scoring='accuracy',  # Optimize for accuracy\n",
    "    verbose=1,  # Display progress\n",
    "    n_jobs=-1  # Use all available CPU cores\n",
    ")\n",
    "\n",
    "# Perform the grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(f\"Best Cross-Validation Accuracy: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_mlp_model = grid_search.best_estimator_\n",
    "y_pred_mlp = best_mlp_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy on the test set\n",
    "accuracy_mlp = accuracy_score(y_test, y_pred_mlp)\n",
    "print(f\"Test Set Accuracy: {accuracy_mlp:.4f}\")\n",
    "\n",
    "# Generate and print confusion matrix and classification report\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_mlp))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_mlp))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naives Bayes hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'alpha': [0.1, 0.5, 1.0, 2.0, 5.0],  # Smoothing parameters\n",
    "}\n",
    "\n",
    "# Initialize the model\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=nb_model,\n",
    "    param_grid=param_grid,\n",
    "    cv=3, \n",
    "    scoring='accuracy',  # Evaluate using accuracy\n",
    "    verbose=1,  # Print progress\n",
    "    n_jobs=-1  # Use all available CPU cores\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lisoh\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "8 fits failed out of a total of 15.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\lisoh\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\lisoh\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\lisoh\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\naive_bayes.py\", line 732, in fit\n",
      "    X, y = self._check_X_y(X, y)\n",
      "  File \"C:\\Users\\lisoh\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\naive_bayes.py\", line 578, in _check_X_y\n",
      "    return self._validate_data(X, y, accept_sparse=\"csr\", reset=reset)\n",
      "  File \"C:\\Users\\lisoh\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py\", line 650, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\lisoh\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 1301, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"C:\\Users\\lisoh\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 1012, in check_array\n",
      "    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n",
      "  File \"C:\\Users\\lisoh\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\_array_api.py\", line 745, in _asarray_with_order\n",
      "    array = numpy.asarray(array, order=order, dtype=dtype)\n",
      "  File \"C:\\Users\\lisoh\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\generic.py\", line 2152, in __array__\n",
      "    values = self._values\n",
      "  File \"C:\\Users\\lisoh\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\frame.py\", line 1127, in _values\n",
      "    return ensure_wrapped_if_datetimelike(self.values)\n",
      "  File \"C:\\Users\\lisoh\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\frame.py\", line 12664, in values\n",
      "    return self._mgr.as_array()\n",
      "  File \"C:\\Users\\lisoh\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\internals\\managers.py\", line 1694, in as_array\n",
      "    arr = self._interleave(dtype=dtype, na_value=na_value)\n",
      "  File \"C:\\Users\\lisoh\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\internals\\managers.py\", line 1727, in _interleave\n",
      "    result = np.empty(self.shape, dtype=dtype)\n",
      "numpy._core._exceptions._ArrayMemoryError: Unable to allocate 706. MiB for an array with shape (2999, 30863) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\lisoh\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\lisoh\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\lisoh\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\naive_bayes.py\", line 732, in fit\n",
      "    X, y = self._check_X_y(X, y)\n",
      "  File \"C:\\Users\\lisoh\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\naive_bayes.py\", line 578, in _check_X_y\n",
      "    return self._validate_data(X, y, accept_sparse=\"csr\", reset=reset)\n",
      "  File \"C:\\Users\\lisoh\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py\", line 650, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\lisoh\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 1301, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"C:\\Users\\lisoh\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\", line 1012, in check_array\n",
      "    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n",
      "  File \"C:\\Users\\lisoh\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\_array_api.py\", line 745, in _asarray_with_order\n",
      "    array = numpy.asarray(array, order=order, dtype=dtype)\n",
      "  File \"C:\\Users\\lisoh\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\generic.py\", line 2152, in __array__\n",
      "    values = self._values\n",
      "  File \"C:\\Users\\lisoh\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\frame.py\", line 1127, in _values\n",
      "    return ensure_wrapped_if_datetimelike(self.values)\n",
      "  File \"C:\\Users\\lisoh\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\frame.py\", line 12664, in values\n",
      "    return self._mgr.as_array()\n",
      "  File \"C:\\Users\\lisoh\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\internals\\managers.py\", line 1694, in as_array\n",
      "    arr = self._interleave(dtype=dtype, na_value=na_value)\n",
      "  File \"C:\\Users\\lisoh\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\internals\\managers.py\", line 1727, in _interleave\n",
      "    result = np.empty(self.shape, dtype=dtype)\n",
      "numpy._core._exceptions._ArrayMemoryError: Unable to allocate 706. MiB for an array with shape (2999, 30864) and data type float64\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\lisoh\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_search.py:1103: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'alpha': 0.1}\n",
      "Best Cross-Validation Accuracy: nan\n",
      "Test Set Accuracy: 0.9313\n",
      "Confusion Matrix:\n",
      "[[9355  522]\n",
      " [ 842 9122]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Ham       0.92      0.95      0.93      9877\n",
      "        Spam       0.95      0.92      0.93      9964\n",
      "\n",
      "    accuracy                           0.93     19841\n",
      "   macro avg       0.93      0.93      0.93     19841\n",
      "weighted avg       0.93      0.93      0.93     19841\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform the grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(f\"Best Cross-Validation Accuracy: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_nb_model = grid_search.best_estimator_\n",
    "y_pred_nb = best_nb_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy on the test set\n",
    "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
    "print(f\"Test Set Accuracy: {accuracy_nb:.4f}\")\n",
    "\n",
    "# Generate and print confusion matrix and classification report\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_nb))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boost Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Encode the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)  # Encode 'Ham' -> 0, 'Spam' -> 1\n",
    "y_test_encoded = label_encoder.transform(y_test)  # Encode test labels\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],  # Number of trees\n",
    "    'max_depth': [3, 5, 7],  # Maximum depth of trees\n",
    "}\n",
    "\n",
    "# Initialize the XGBClassifier\n",
    "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,  # 3-fold cross-validation for faster results\n",
    "    scoring='accuracy',\n",
    "    verbose=True,\n",
    "    n_jobs=-1  # Use all available CPU cores\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    }
   ],
   "source": [
    "# Perform the grid search with the encoded training labels\n",
    "grid_search.fit(X_train, y_train_encoded)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(f\"Best Cross-Validation Accuracy: {grid_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the best model on the test set\n",
    "best_xgb_model = grid_search.best_estimator_\n",
    "y_pred_tuned = best_xgb_model.predict(X_test)\n",
    "\n",
    "# Decode predictions back to original labels\n",
    "y_pred_decoded = label_encoder.inverse_transform(y_pred_tuned)\n",
    "\n",
    "# Test set evaluation\n",
    "print(\"Tuned Gradient Boosting Results:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_decoded):.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_decoded))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_decoded))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
